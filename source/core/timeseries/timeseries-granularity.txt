.. _timeseries-granularity:

====================================
Set Granularity for Time Series Data
====================================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: singlecol

.. meta::
   :description: Time series, granularity, IOT
   :keywords: Time series, granularity, IOT

When you create a :ref:`time series collection 
<manual-timeseries-collection>`, MongoDB automatically creates a ``system.buckets`` 
:ref:`system collection <metadata-system-collections>` based on the ``granularity`` value you specify, and groups 
documents into those buckets.

.. note::

   You must be running MongoDB 5.0.1 or later in order to change a
   time series collection's granularity after the collection has been
   created. See :ref:`MongoDB 5.0 known issues
   <5.0-known-issue-granularity>`.

When you create a :ref:`time series collection
<manual-timeseries-collection>`, you can specify the
``granularity`` parameter. The ``granularity`` determines how data 
in the time series collection is stored internally. For details about 
how MongoDB stores time series data, see :ref:`flexible-bucketing`.
 
By default, ``granularity`` is set to ``"seconds"``. To optimize  
data storage, set the ``granularity`` to a value that is closest 
to the ingestion rate for your data source as specified by
the ``metaField`` field. The ingestion rate is the time span between 
consecutive incoming measurements that have the same unique value for 
the ``metaField``.

Consider the following example:

.. code-block:: javascript

   db.createCollection(
       "weather24h",
       {
          timeseries: {
             timeField: "timestamp",
             metaField: "metadata",
             granularity: "minutes"
          },
          expireAfterSeconds: 86400
       }
   )

If your ``metaField`` data identifies weather sensors and
you ingest data from each individual sensor once every 5 minutes, you
should choose ``"minutes"``. Even if you have thousands of sensors and
the data coming in from different sensors is only seconds apart, the
``granularity`` should still be based on the ingestion rate for one
sensor that is uniquely identified by its metadata. 

In the following table, you can see the max time span of data that is
stored together for each ``granularity`` value:

.. list-table::
  :header-rows: 1
  :widths: 40 60

  * - ``granularity``

    - Covered Time Span

  * - ``"seconds"`` (default)

    - one hour

  * - ``"minutes"``

    - 24 hours

  * - ``"hours"``

    - 30 days


.. seealso::

   :ref:`Timing of Automatic Removal
   <timeseries-collection-delete-operations-timing>`

Retrieve the ``granularity`` of a Time Series Collection
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To retrieve the current value of ``granularity``, use the
:dbcommand:`listCollections` command:

.. code-block:: javascript

   db.runCommand( { listCollections: 1 } )

The result document contains a document for the time series collection
which contains the ``options.timeseries.granularity`` field.

.. code-block:: javascript
  :copyable: false

  {
      cursor: {
         id: <number>,
         ns: 'test.$cmd.listCollections',
         firstBatch: [
           {
              name: <string>,
              type: 'timeseries',
              options: {
                 expireAfterSeconds: <number>,
                 timeseries: {
                    timeField: <string>,
                    metaField: <string>,
                    granularity: <string>,
                    bucketMaxSpanSeconds: <number>
                 }
              },
              ...
           },
           ...
         ]
      }
   }

Change the ``granularity`` of a Time Series Collection
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Using the "granularity" Field
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The following table shows the maximum time interval included in one 
bucket of data when using a given ``granularity`` value:

.. include:: /includes/table-timeseries-granularity-intervals.rst

By default, ``granularity`` is set to ``seconds``. You can improve performance by setting the ``granularity`` value to the 
closest match to the time span between incoming measurements from the 
same data source. For example, if you are recording weather data from 
thousands of sensors but only record data from each sensor once per 5 
minutes, set ``granularity`` to ``"minutes"``.

.. code-block:: javascript

   db.runCommand({
      collMod: "weather24h",
      timeseries: { granularity: "hours" }
   })

Once set, you cannot decrease granularity. For example, if granularity
is set to ``minutes``, you can increase it to ``hours``, but you cannot
decrease it to ``seconds``.

.. note::

   You cannot modify the ``granularity`` of a sharded time series
   collection.

.. _flexible-bucketing:

Flexible Bucketing
~~~~~~~~~~~~~~~~~~

MongoDB groups incoming time series data into buckets. By setting the 
``granularity`` parameter, you control how frequently data is bucketed 
based on the ingestion rate of your data.

Starting in MongoDB 6.3, you can specify the bucket boundaries to 
more accurately control how time series data is bucketed. Use the 
following parameters:

- ``bucketMaxSpanSeconds``, the maximum time span between measurements
  in a bucket.
- ``bucketRoundingSeconds``, the time interval that determines the 
  starting timestamp for a new bucket.

.. note::

   If you want to specify the bucket boundaries:

   - You must set both ``bucketMaxSpanSeconds`` and ``bucketRoundingSeconds``.
   - Both parameters must have the same value.
   - You can't additionally set the ``granularity`` parameter.

Consider the following time series collection:

.. code-block:: javascript
      
   db. createCollection(
      "weather24h", 
      {
         timeseries: {
            timeField: "timestamp",
            metaField: "metadata",
            bucketMaxSpanSeconds: 60,
            bucketRoundingSeconds: 60
         }
      }   
   )

Each bucket has a maximum time span of 60 seconds. When MongoDB opens a 
new bucket, the starting timestamp is rounded down to the nearest 60-second 
interval.

For example, if you insert a new measurement into the collection with a
timestamp of ``11:59:59``, the measurement is added to the bucket 
with boundaries between ``11:59:00`` and ``12:00:00`` (non-inclusive).
If the bucket doesn't exist, the starting timestamp of the new bucket 
is determined by rounding ``11:59:59`` down to ``11:59:00``.

For more information on time series parameters, see :ref:`time-series-fields`.
