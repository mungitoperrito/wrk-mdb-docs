# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2008-2016
# This file is distributed under the same license as the mongodb-manual package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: mongodb-manual 3.4\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-12-08 12:02-0500\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../source/faq/diagnostics.txt:5
# 2b9d73757e3f4ae4ac5b95f026c033f4
msgid "FAQ: MongoDB Diagnostics"
msgstr ""

#: ../source/faq/diagnostics.txt:0
# a505063587c341f68f24e1e9113a56a0
msgid "On this page"
msgstr ""

#: ../source/faq/diagnostics.txt:15
# 558336825a654ce486bee9a06751b576
msgid "This document provides answers to common diagnostic questions and issues."
msgstr ""

#: ../source/faq/diagnostics.txt:18
# 53897e18a3db48cd977cce0c422262d9
msgid "If you don't find the answer you're looking for, check the :doc:`complete list of FAQs </faq>` or post your question to the `MongoDB User Mailing List <https://groups.google.com/forum/?fromgroups#!forum/mongodb-user>`_."
msgstr ""

#: ../source/faq/diagnostics.txt:23
# ea8dfeec467c4dab9577ece164949012
msgid "Where can I find information about a ``mongod`` process that stopped running unexpectedly?"
msgstr ""

#: ../source/faq/diagnostics.txt:25
# 62878f7c8788408b89faffbd8ad33bfe
msgid "If :program:`mongod` shuts down unexpectedly on a UNIX or UNIX-based platform, and if :program:`mongod` fails to log a shutdown or error message, then check your system logs for messages pertaining to MongoDB. For example, for logs located in ``/var/log/messages``, use the following commands:"
msgstr ""

#: ../source/faq/diagnostics.txt:39
# ff88ae3b65bd45968bc7e5aca142efff
msgid "Does TCP ``keepalive`` time affect MongoDB Deployments?"
msgstr ""

#: ../source/faq/diagnostics.txt:41
# 747a624f6c074bbeacb86aa25d2f8ee5
msgid "If you experience socket errors between clients and servers or between members of a sharded cluster or replica set that do not have other reasonable causes, check the TCP keepalive value (e.g. on Linux systems store, the ``tcp_keepalive_time`` value). A common keepalive period is ``7200`` seconds (2 hours); however, different distributions and OS X may have different settings."
msgstr ""

#: ../source/faq/diagnostics.txt:48
# 01b1489e0059499fac47dea5d41f7b94
msgid "For MongoDB, you will have better results with shorter keepalive periods, on the order of ``120`` seconds (two minutes)."
msgstr ""

#: ../source/faq/diagnostics.txt:51
# b9cedc5d405e4c59991fab58c5ed83f4
msgid "If your MongoDB deployment experiences keepalive-related issues, you must alter the keep alive value on *all* machines hosting MongoDB processes. This includes all machines hosting :program:`mongos` or :program:`mongod` servers and all machines hosting client processes that connect to MongoDB."
msgstr ""

#: ../source/faq/diagnostics.txt:59
# 0602a4d5e08044f7b371e895be3f83d2
msgid "For non-Linux systems, values greater than or equal to 600 seconds (10 minutes) will be ignored by :program:`mongod` and :program:`mongos`. For Linux, values greater than 300 seconds (5 minutes) will be overridden on the :program:`mongod` and :program:`mongos` sockets with a maximum of 300 seconds."
msgstr ""

#: ../source/includes/fact-tcp-keepalive-linux.rst:1
# 9224bf90d0ac4dcf879d2ae6e0921e76
msgid "**On Linux systems**:"
msgstr ""

#: ../source/includes/fact-tcp-keepalive-linux.rst:3
# 792655405a5d49abbb3c8393d76971ce
msgid "To view the keep alive setting, you can use one of the following commands:"
msgstr ""

#: ../source/includes/fact-tcp-keepalive-linux.rst:10
#: ../source/includes/fact-tcp-keepalive-linux.rst:25
# a43e3d5c01084116ace57e70d3f148bd
# ef2b6eb9e5c943b799677868914016fd
msgid "Or:"
msgstr ""

#: ../source/includes/fact-tcp-keepalive-linux.rst:16
# 723848d386ed439e8562b44ef1758224
msgid "The value is measured in seconds."
msgstr ""

#: ../source/includes/fact-tcp-keepalive-linux.rst:18
# 0490ba5c0244497990da8dae91e3b177
msgid "To change the ``tcp_keepalive_time`` value, you can use one of the following command:"
msgstr ""

#: ../source/includes/fact-tcp-keepalive-linux.rst:31
# 954c05ca4c9a449baed04567d62ac66d
msgid "These operations do not persist across system reboots. To persist the setting, add the following line to ``/etc/sysctl.conf``:"
msgstr ""

#: ../source/includes/fact-tcp-keepalive-linux.rst:38
# 7bc2a524b1c64f1f8eeec0b3a7d295d9
msgid "On Linux, :program:`mongod` and :program:`mongos` processes limit the keepalive to a maximum of 300 seconds (5 minutes) on their own sockets by overriding keepalive values greater than 5 minutes."
msgstr ""

#: ../source/includes/fact-tcp-keepalive-osx.rst:1
# 91112712695840cdba2b37170b75d128
msgid "**For OS X systems**:"
msgstr ""

#: ../source/includes/fact-tcp-keepalive-osx.rst:3
#: ../source/includes/fact-tcp-keepalive-windows.rst:3
# d104f88fcc7f4de8a69fbbc138416e8e
# 1d31fb94d9444b4b971b07aa7ccc8591
msgid "To view the keep alive setting, issue the following command:"
msgstr ""

#: ../source/includes/fact-tcp-keepalive-osx.rst:9
# bba4cc63097449368d5fa75d7fe8a274
msgid "To change the ``net.inet.tcp.keepinit`` value, you can use the following command:"
msgstr ""

#: ../source/includes/fact-tcp-keepalive-osx.rst:16
# c54f61139a5c4a188f8e7afd8d2c12fd
msgid "The above method for setting the TCP keepalive is not persistent; you will need to reset the value each time you reboot or restart a system. See your operating systemâ€™s documentation for instructions on setting the TCP keepalive value persistently."
msgstr ""

#: ../source/includes/fact-tcp-keepalive-windows.rst:1
# 251c4e1618e54433ace3ec54b276be4b
msgid "**For Windows systems**:"
msgstr ""

#: ../source/includes/fact-tcp-keepalive-windows.rst:9
# 457bedb1e3df40558f16dbaf77d03435
msgid "The registry value is not present by default. The system default, used if the value is absent, is 7200000 *milliseconds* or ``0x6ddd00`` in hexadecimal."
msgstr ""

#: ../source/includes/fact-tcp-keepalive-windows.rst:13
# 7a30b2933eff49a6941b27791b8ca2a7
msgid "To change the ``KeepAliveTime`` value, use the following command in an Administrator :guilabel:`Command Prompt`, where ``<value>`` is expressed in hexadecimal (e.g. 120000 is ``0x1d4c0``):"
msgstr ""

#: ../source/includes/fact-tcp-keepalive-windows.rst:21
# affa4ab0c4574e72acaff0d9061277d4
msgid "Windows users should consider the `Windows Server Technet Article on KeepAliveTime <https://technet.microsoft.com/en-us/library/cc957549.aspx>`_ for more information on setting keep alive for MongoDB deployments on Windows systems."
msgstr ""

#: ../source/faq/diagnostics.txt:71
# 12bf037537824813bf0b635e81dae86e
msgid "You will need to restart :program:`mongod` and :program:`mongos` servers for new system-wide keepalive settings to take effect."
msgstr ""

#: ../source/faq/diagnostics.txt:75
# 813674c1ab1a40c5a1df8447266dfa2c
msgid "Why does MongoDB log so many \"Connection Accepted\" events?"
msgstr ""

#: ../source/faq/diagnostics.txt:77
# adeac4faa78d493597c4edd7805feb1f
msgid "If you see a very large number connection and re-connection messages in your MongoDB log, then clients are frequently connecting and disconnecting to the MongoDB server. This is normal behavior for applications that do not use request pooling, such as CGI. Consider using FastCGI, an Apache Module, or some other kind of persistent application server to decrease the connection overhead."
msgstr ""

#: ../source/faq/diagnostics.txt:84
# 1cfe246a380d4cd0b04fc906ec8ba6a8
msgid "If these connections do not impact your performance you can use the run-time :setting:`~systemLog.quiet` option or the command-line option :option:`--quiet <mongod --quiet>` to suppress these messages from the log."
msgstr ""

#: ../source/faq/diagnostics.txt:90
# ae61a184232340f38a2f36cf280f7624
msgid "What tools are available for monitoring MongoDB?"
msgstr ""

#: ../source/faq/diagnostics.txt:92
# 4641ce9b9b05433596d2341fa58c259e
msgid "The |mms-home| and :products:`Ops Manager, an on-premise solution available in MongoDB Enterprise Advanced </mongodb-enterprise-advanced?jmp=docs>` include monitoring functionality, which collects data from running MongoDB deployments and provides visualization and alerts based on that data."
msgstr ""

#: ../source/faq/diagnostics.txt:98
# f66b34c56e7a4cdaad928d44732c7cd8
msgid "For more information, see also the |mms-docs| and :opsmgr:`Ops Manager documentation </application>`."
msgstr ""

#: ../source/faq/diagnostics.txt:101
# 192f5542a0c74a35b850e285889e5838
msgid "A full list of third-party tools is available as part of the :doc:`/administration/monitoring/` documentation."
msgstr ""

#: ../source/faq/diagnostics.txt:109
# 53d377b032df4c9ebaf1a2bf020cca57
msgid "Memory Diagnostics for the MMAPv1 Storage Engine"
msgstr ""

#: ../source/faq/diagnostics.txt:112
# 7d4064fe2611475383b35441fda29524
msgid "Do I need to configure swap space?"
msgstr ""

#: ../source/faq/diagnostics.txt:114
# 5ff6a92429a24047b1e04ea2cc2cafa1
msgid "Always configure systems to have swap space. Without swap, your system may not be reliant in some situations with extreme memory constraints, memory leaks, or multiple programs using the same memory.  Think of the swap space as something like a steam release valve that allows the system to release extra pressure without affecting the overall functioning of the system."
msgstr ""

#: ../source/faq/diagnostics.txt:121
# 6ad61dd8e1d74230a0992be2665a56a1
msgid "Nevertheless, systems running MongoDB *do not* need swap for routine operation. Database files are :ref:`memory-mapped <faq-storage-memory-mapped-files>` and should constitute most of your MongoDB memory use. Therefore, it is unlikely that :program:`mongod` will ever use any swap space in normal operation. The operating system will release memory from the memory mapped files without needing swap and MongoDB can write data to the data files without needing the swap system."
msgstr ""

#: ../source/faq/diagnostics.txt:133
# 3dd65853924346b8a13be05262d58a6b
msgid "What is a \"working set\"?"
msgstr ""

#: ../source/faq/diagnostics.txt:135
# fb0575434136460ebb4618ebef295c9f
msgid "The *working set* is the portion of your data that clients access most often."
msgstr ""

#: ../source/faq/diagnostics.txt:139
#: ../source/faq/diagnostics.txt:214
# da77910a355542b4a32d241048ff8986
# edf7d489d26e4ce1975edf50828d6f2d
msgid "Must my working set size fit RAM?"
msgstr ""

#: ../source/faq/diagnostics.txt:141
# 0dfc5234a3514866b036397d4d1befbb
msgid "Your working set should stay in memory to achieve good performance. Otherwise many random disk IO's will occur, and unless you are using SSD, this can be quite slow."
msgstr ""

#: ../source/faq/diagnostics.txt:145
# 24c461d34e69476aa9db4fd208724423
msgid "One area to watch specifically in managing the size of your working set is index access patterns. If you are inserting into indexes at random locations (as would happen with id's that are randomly generated by hashes), you will continually be updating the whole index. If instead you are able to create your id's in approximately ascending order (for example, day concatenated with a random id), all the updates will occur at the right side of the b-tree and the working set size for index pages will be much smaller."
msgstr ""

#: ../source/faq/diagnostics.txt:154
# 64559f541b384924a3b23a7d568d15b9
msgid "It is fine if databases and thus virtual size are much larger than RAM."
msgstr ""

#: ../source/faq/diagnostics.txt:157
#: ../source/faq/diagnostics.txt:221
# 0bb150fcc675486b8d0e84d45180d2f9
# 286ca2e996f24eaa976843008164f470
msgid "How do I calculate how much RAM I need for my application?"
msgstr ""

#: ../source/faq/diagnostics.txt:161
# be7c0575fe844ff996e89eacd1bac123
msgid "The amount of RAM you need depends on several factors, including but not limited to:"
msgstr ""

#: ../source/faq/diagnostics.txt:164
# c5b5b73eb93e44459419322bdad46d9b
msgid "The relationship between :doc:`database storage </faq/storage>` and working set."
msgstr ""

#: ../source/faq/diagnostics.txt:166
# 1f8737e1a1014ab3abf679f4c95e970c
msgid "The operating system's cache strategy for LRU (Least Recently Used)"
msgstr ""

#: ../source/faq/diagnostics.txt:168
# d0c4d31b0600481182b99c5a39594e8b
msgid "The impact of :doc:`journaling </core/journaling>`"
msgstr ""

#: ../source/faq/diagnostics.txt:170
# c1ed8ca9afbd48938edc6a2de5e5cdd3
msgid "The number or rate of page faults and other |MMS| gauges to detect when you need more RAM"
msgstr ""

#: ../source/faq/diagnostics.txt:173
# b9ebc178b82846cd8c7f9de91cab28ed
msgid "Each database connection thread will need up to 1 MB of RAM."
msgstr ""

#: ../source/faq/diagnostics.txt:175
# 5d31de7ed5984afa8a2c928806cfcd8d
msgid "MongoDB defers to the operating system when loading data into memory from disk. It simply :ref:`memory maps <faq-storage-memory-mapped-files>` all its data files and relies on the operating system to cache data. The OS typically evicts the least-recently-used data from RAM when it runs low on memory. For example if clients access  indexes more frequently than documents, then indexes will more likely stay in RAM, but it depends on your particular usage."
msgstr ""

#: ../source/faq/diagnostics.txt:183
# 44a6768a650445749360ae3ed3c6d78f
msgid "To calculate how much RAM you need, you must calculate your working set size, or the portion of your data that clients use most often. This depends on your access patterns, what indexes you have, and the size of your documents. Because MongoDB uses a thread per connection model, each database connection also will need up to 1 MB of RAM, whether active or idle."
msgstr ""

#: ../source/faq/diagnostics.txt:189
# 19b7faf51c6345e6bd1f55753df6a6bc
msgid "If page faults are infrequent, your working set fits in RAM. If fault rates rise higher than that, you risk performance degradation. This is less critical with SSD drives than with spinning disks."
msgstr ""

#: ../source/faq/diagnostics.txt:195
# 74b5e272fd4442d5b58f781fe99b500b
msgid "How do I read memory statistics in the UNIX ``top`` command"
msgstr ""

#: ../source/faq/diagnostics.txt:197
# 04473fac7b9d4f39b773673c1f6960d7
msgid "Because :program:`mongod` uses :ref:`memory-mapped files <faq-storage-memory-mapped-files>`, the memory statistics in ``top`` require interpretation in a special way. On a large database, ``VSIZE`` (virtual bytes) tends to be the size of the entire database. If the :program:`mongod` doesn't have other processes running, ``RSIZE`` (resident bytes) is the total memory of the machine, as this counts file system cache contents."
msgstr ""

#: ../source/faq/diagnostics.txt:205
# c1a27f7d5e824fb2b00312e336bccafc
msgid "For Linux systems, use the ``vmstat`` command to help determine how the system uses memory. On OS X systems use ``vm_stat``."
msgstr ""

#: ../source/faq/diagnostics.txt:211
# 982561b7e3384bc7b5b5b49cb1eaee61
msgid "Memory Diagnostics for the WiredTiger Storage Engine"
msgstr ""

#: ../source/faq/diagnostics.txt:216
# 6dd7c34eca284ce596a53d50b4a30aa2
msgid "No."
msgstr ""

#: ../source/includes/extracts/wt-cache-eviction.rst:1
# da3d8d12263b41a2bc653d50e96f0741
msgid "If the cache does not have enough space to load additional data, WiredTiger evicts pages from the cache to free up space."
msgstr ""

#: ../source/includes/extracts/wt-cache-additional-constraints-mongod-config.rst:3
#: ../source/includes/extracts/wt-cache-additional-constraints-mongod-config.rst:3
# 0ff597d6762d4b259e8f3888814d255c
# 41f4f6d25ba3407288998b9fdab08e81
msgid "The :setting:`storage.wiredTiger.engineConfig.cacheSizeGB` limits the size of the WiredTiger internal cache. The operating system will use the available free memory for filesystem cache, which allows the compressed MongoDB data files to stay in memory. In addition, the operating system will use any free RAM to buffer file system blocks and file system cache."
msgstr ""

#: ../source/includes/extracts/wt-cache-additional-constraints-mongod-config.rst:10
#: ../source/includes/extracts/wt-cache-additional-constraints-mongod-config.rst:10
# 01bedba840e24499a03ef0007bfb4ddb
# f33adf5061f94835ad0d5505870d9a8b
msgid "To accommodate the additional consumers of RAM, you may have to decrease WiredTiger internal cache size."
msgstr ""

#: ../source/includes/extracts/wt-cache-additional-constraints-mongod-config.rst:13
#: ../source/includes/extracts/wt-cache-additional-constraints-mongod-config.rst:13
# 56462cf4e34a4201823003ef6a410c67
# 0b287eb54ffb4288a323aa4f7d3a45be
msgid "The default WiredTiger internal cache size value assumes that there is a single :program:`mongod` instance per machine. If a single machine contains multiple MongoDB instances, then you should decrease the setting to accommodate the other :program:`mongod` instances."
msgstr ""

#: ../source/includes/extracts/wt-cache-additional-constraints-mongod-config.rst:19
#: ../source/includes/extracts/wt-cache-additional-constraints-mongod-config.rst:19
# 91b2c9c6fe084d5a801557e6de7ce922
# e9063687cfda40c5bf088eaecd4bb13f
msgid "If you run :program:`mongod` in a container (e.g. ``lxc``, ``cgroups``, Docker, etc.) that does *not* have access to all of the RAM available in a system, you must set :setting:`storage.wiredTiger.engineConfig.cacheSizeGB` to a value less than the amount of RAM available in the container. The exact amount depends on the other processes running in the container."
msgstr ""

#: ../source/includes/extracts/wt-cache-size.rst:4
# 4bac962067df4cfeaea7e2b7797379d6
msgid "To see statistics on the cache and eviction, use the :dbcommand:`serverStatus` command. The :serverstatus:`wiredTiger.cache` field holds the information on the cache and eviction."
msgstr ""

#: ../source/includes/extracts/wt-cache-size.rst:49
# 7045d50c46ea490eb6bb0c87df2ec641
msgid "For an explanation of some key cache and eviction statistics, such as :serverstatus:`wiredTiger.cache.bytes currently in the cache` and :serverstatus:`wiredTiger.cache.tracked dirty bytes in the cache`, see :serverstatus:`wiredTiger.cache`."
msgstr ""

#: ../source/includes/extracts/wt-cache-setting.rst:1
#: ../source/includes/extracts/wt-cache-setting.rst:1
# 9351f8da8c324aabace0928a568b87c5
# c385b66b446d4428ae8ad8d40d7b2e8e
msgid "To adjust the size of the WiredTiger internal cache, see :setting:`storage.wiredTiger.engineConfig.cacheSizeGB` and :option:`--wiredTigerCacheSizeGB`. Avoid increasing the WiredTiger internal cache size above its default value."
msgstr ""

#: ../source/includes/extracts/wt-cache-utilization.rst:1
# 6fd3895c60ed4356adf2b459b1bc5609
msgid "With WiredTiger, MongoDB utilizes both the WiredTiger internal cache and the filesystem cache."
msgstr ""

#: ../source/includes/extracts/wt-cache-default-setting.rst:2
# 5749728175e54f45be0a256317c5e918
msgid "Starting in 3.4, the WiredTiger internal cache, by default, will use the larger of either:"
msgstr ""

#: ../source/includes/extracts/wt-cache-default-setting.rst:5
# 80e1a3170df0415381c61d981416326e
msgid "50% of RAM minus 1 GB, or"
msgstr ""

#: ../source/includes/extracts/wt-cache-default-setting.rst:7
# 1bab7791791d4258815681c1bdedfb33
msgid "256 MB."
msgstr ""

#: ../source/includes/extracts/wt-filesystem-cache.rst:1
# 5fa14cc8c60c4c458f1a672f08af43b2
msgid "Via the filesystem cache, MongoDB automatically uses all free memory that is not used by the WiredTiger cache or by other processes. Data in the filesystem cache is compressed."
msgstr ""

#: ../source/includes/extracts/wt-configure-cache.rst:7
# 8dc04e0afc344abdb40bea99394febe5
msgid "To view statistics on the cache and eviction rate, see the :serverstatus:`wiredTiger.cache` field returned from the :dbcommand:`serverStatus` command."
msgstr ""

#: ../source/faq/diagnostics.txt:226
# 838df8cd7b134587aa29390faa54c732
msgid "Sharded Cluster Diagnostics"
msgstr ""

#: ../source/faq/diagnostics.txt:228
# 7ea9f1e0e8594e97bf8ff7bbc30c3818
msgid "The two most important factors in maintaining a successful sharded cluster are:"
msgstr ""

#: ../source/faq/diagnostics.txt:230
# f47a53c952bf412a90a32556180dfaf1
msgid ":ref:`choosing an appropriate shard key <sharding-internals-shard-keys>` and"
msgstr ""

#: ../source/faq/diagnostics.txt:232
# 1a2365b67aee4834ad1b7c751084f482
msgid ":ref:`sufficient capacity to support current and future operations <sharding-capacity-planning>`."
msgstr ""

#: ../source/faq/diagnostics.txt:235
# fb1bb0b2c7154b258d569e697d990197
msgid "You can prevent most issues encountered with sharding by ensuring that you choose the best possible :term:`shard key` for your deployment and ensure that you are always adding additional capacity to your cluster well before the current resources become saturated. Continue reading for specific issues you may encounter in a production environment."
msgstr ""

#: ../source/faq/diagnostics.txt:244
# 2be37af0e79d48228a682a1d98cb75b2
msgid "In a new sharded cluster, why does all data remains on one shard?"
msgstr ""

#: ../source/faq/diagnostics.txt:246
# dc738badee3f4421a8d89a1ef51a038d
msgid "Your cluster must have sufficient data for sharding to make sense. Sharding works by migrating chunks between the shards until each shard has roughly the same number of chunks."
msgstr ""

#: ../source/faq/diagnostics.txt:250
# 6bd83cab38524f3cb20c0079a46627bf
msgid "The default chunk size is 64 megabytes. MongoDB will not begin migrations until the imbalance of chunks in the cluster exceeds the :ref:`migration threshold <sharding-migration-thresholds>`. This behavior helps prevent unnecessary chunk migrations, which can degrade the performance of your cluster as a whole."
msgstr ""

#: ../source/faq/diagnostics.txt:256
# a442fb5e7ac74f72b7c98f05ba6ac9f5
msgid "If you have just deployed a sharded cluster, make sure that you have enough data to make sharding effective. If you do not have sufficient data to create more than eight 64 megabyte chunks, then all data will remain on one shard. Either lower the :ref:`chunk size <sharding-chunk-size>` setting, or add more data to the cluster."
msgstr ""

#: ../source/faq/diagnostics.txt:262
# 8492169ec92d4adabbef3116f7127886
msgid "As a related problem, the system will split chunks only on inserts or updates, which means that if you configure sharding and do not continue to issue insert and update operations, the database will not create any chunks. You can either wait until your application inserts data *or* :doc:`split chunks manually </tutorial/split-chunks-in-sharded-cluster>`."
msgstr ""

#: ../source/faq/diagnostics.txt:268
# 787f6ec0e1a544deb5bd33b8c9100683
msgid "Finally, if your shard key has a low :ref:`cardinality <sharding-shard-key-cardinality>`, MongoDB may not be able to create sufficient splits among the data."
msgstr ""

#: ../source/faq/diagnostics.txt:273
# 8a397f6dbc9d420abe629b35bc8ddf43
msgid "Why would one shard receive a disproportion amount of traffic in a sharded cluster?"
msgstr ""

#: ../source/faq/diagnostics.txt:275
# 1b8e07a265894388af93090b553ca895
msgid "In some situations, a single shard or a subset of the cluster will receive a disproportionate portion of the traffic and workload. In almost all cases this is the result of a shard key that does not effectively allow :ref:`write scaling <sharding-shard-key-write-scaling>`."
msgstr ""

#: ../source/faq/diagnostics.txt:280
# 28f972a8940a44b58a5783eea28f6a55
msgid "It's also possible that you have \"hot chunks.\" In this case, you may be able to solve the problem by splitting and then migrating parts of these chunks."
msgstr ""

#: ../source/faq/diagnostics.txt:284
# 654a25ec27fd4edb94649d9ebf6b127b
msgid "In the worst case, you may have to consider re-sharding your data and :ref:`choosing a different shard key <sharding-internals-choose-shard-key>` to correct this pattern."
msgstr ""

#: ../source/faq/diagnostics.txt:289
# 0fa8c2a86e184907ade1c4d787f5a346
msgid "What can prevent a sharded cluster from balancing?"
msgstr ""

#: ../source/faq/diagnostics.txt:291
# 630e79def0cd4563af9dfb6c93e3f4fc
msgid "If you have just deployed your sharded cluster, you may want to consider the :ref:`troubleshooting suggestions for a new cluster where data remains on a single shard <sharding-troubleshooting-not-splitting>`."
msgstr ""

#: ../source/faq/diagnostics.txt:295
# bd33165b296b47d29f6a5ffa3673f7be
msgid "If the cluster was initially balanced, but later developed an uneven distribution of data, consider the following possible causes:"
msgstr ""

#: ../source/faq/diagnostics.txt:298
# ede0e5ffb1054d28a8dc6f8b2a579c5f
msgid "You have deleted or removed a significant amount of data from the cluster. If you have added additional data, it may have a different distribution with regards to its shard key."
msgstr ""

#: ../source/faq/diagnostics.txt:302
# 2e991c96bcd34d159484dd1eacaaa15b
msgid "Your :term:`shard key` has low :ref:`cardinality <sharding-shard-key-cardinality>` and MongoDB cannot split the chunks any further."
msgstr ""

#: ../source/faq/diagnostics.txt:305
# 677cd7d002c6479a8be087339591c2fe
msgid "Your data set is growing faster than the balancer can distribute data around the cluster. This is uncommon and typically is the result of:"
msgstr ""

#: ../source/faq/diagnostics.txt:309
# f4f4c3d387394b0b9431bdebbee160f2
msgid "a :ref:`balancing window <sharding-schedule-balancing-window>` that is too short, given the rate of data growth."
msgstr ""

#: ../source/faq/diagnostics.txt:312
# 6342df98f30949839af026a6db7d82fb
msgid "an uneven distribution of :ref:`write operations <sharding-shard-key-write-scaling>` that requires more data migration. You may have to choose a different shard key to resolve this issue."
msgstr ""

#: ../source/faq/diagnostics.txt:317
# 374cc9b6253e468591a4419f103154fd
msgid "poor network connectivity between shards, which may lead to chunk migrations that take too long to complete. Investigate your network configuration and interconnections between shards."
msgstr ""

#: ../source/faq/diagnostics.txt:322
# 93a193d563054cf3a1472fb82a947b25
msgid "Why do chunk migrations affect sharded cluster performance?"
msgstr ""

#: ../source/faq/diagnostics.txt:324
# 6fe75676d9294a2b999de5f06ef2627d
msgid "If migrations impact your cluster or application's performance, consider the following options, depending on the nature of the impact:"
msgstr ""

#: ../source/faq/diagnostics.txt:327
# 4483d491b124408683648d69ecdf8e24
msgid "If migrations only interrupt your clusters sporadically, you can limit the :ref:`balancing window <sharding-schedule-balancing-window>` to prevent balancing activity during peak hours. Ensure that there is enough time remaining to keep the data from becoming out of balance again."
msgstr ""

#: ../source/faq/diagnostics.txt:333
# 029c77c780764dcca53c49accd9a2600
msgid "If the balancer is always migrating chunks to the detriment of overall cluster performance:"
msgstr ""

#: ../source/faq/diagnostics.txt:336
# 9241ace6d3fe46dca45a7e78474ebe7f
msgid "You may want to attempt :doc:`decreasing the chunk size </tutorial/modify-chunk-size-in-sharded-cluster>` to limit the size of the migration."
msgstr ""

#: ../source/faq/diagnostics.txt:339
# 80c485d3f4f8493c950f2db50d947af6
msgid "Your cluster may be over capacity, and you may want to attempt to :ref:`add one or two shards <sharding-procedure-add-shard>` to the cluster to distribute load."
msgstr ""

#: ../source/faq/diagnostics.txt:343
# 78cc66de76ba46fe8c72d45a2c7c61f8
msgid "It's also possible that your shard key causes your application to direct all writes to a single shard. This kind of activity pattern can require the balancer to migrate most data soon after writing it. Consider redeploying your cluster  with a shard key that provides better :ref:`write scaling <sharding-shard-key-write-scaling>`."
msgstr ""

